# ğŸ“„ Otomatik Makale Analizi ve Ã–zetleyici (End-to-End LLM Ã‡Ã¶zÃ¼mÃ¼)
Bu proje, yapay zeka (LLM) teknolojilerini kullanarak PDF biÃ§imindeki bilimsel makaleleri otomatik olarak analiz eder ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir Ã¶zete dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. 
Modeli harici bir API'ye baÄŸÄ±mlÄ± olmadan, tamamen yerli (kendi sunucusunda) Ã§alÄ±ÅŸtÄ±rÄ±lan bir LLM Ã¼zerine kurulmuÅŸtur.

Bu proje, End-to-End bir Ã§Ã¶zÃ¼m sunar: 
Veri Ä°ÅŸleme (PDF Parsing) -> YapÄ±landÄ±rÄ±lmÄ±ÅŸ LLM Ä°zleme -> DaÄŸÄ±tÄ±labilir API (FastAPI) -> KullanÄ±cÄ± ArayÃ¼zÃ¼ (Streamlit) -> Docker 

# ğŸš€ CanlÄ± Demo
Projenin Ã§alÄ±ÅŸan versiyonunu [BURAYA YAYINLADIÄINIZ HUGGING FACE / RENDER URL'SÄ°NÄ° EKLEYÄ°N] adresinden deneyimleyebilirsiniz.

# ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ± (Tech Stack)
<table>
  <thead>
    <tr>
      <th>ModÃ¼l</th>
      <th>Teknoloji</th>
      <th>AÃ§Ä±klama</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Model (LLM)</td>
      <td>Mistral-7B-Instruct-v0.2 (Hugging Face)</td>
      <td>Yerel ve kotasÄ±z Ã§alÄ±ÅŸan, 7 milyar parametreli Instruction-Tuned model.</td>
    </tr>
    <tr>
      <td>Backend API</td>
      <td>FastAPI</td>
      <td>YÃ¼ksek performanslÄ±, asenkron Python web Ã§erÃ§evesi. PDF yÃ¼kleme ve LLM ile iletiÅŸimi yÃ¶netir.</td>
    </tr>
    <tr>
      <td>Frontend UI</td>
      <td>Streamlit</td>
      <td>HÄ±zlÄ± prototipleme ve model Ã§Ä±ktÄ±sÄ±nÄ±n gÃ¶rselleÅŸtirilmesi iÃ§in Python tabanlÄ± arayÃ¼z.</td>
    </tr>
    <tr>
      <td>Veri Ä°ÅŸleme</td>
      <td>pdfplumber</td>
      <td>PDF dosyalarÄ±ndan metin Ã§Ä±karma.</td>
    </tr>
    <tr>
      <td>KonteynerleÅŸtirme</td>
      <td>Docker</td>
      <td>UygulamanÄ±n ve model aÄŸÄ±rlÄ±klarÄ±nÄ±n her ortamda (CPU/GPU) aynÄ± ÅŸekilde Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.</td>
    </tr>
    <tr>
      <td>DaÄŸÄ±tÄ±m (Ops.)</td>
      <td>Hugging Face Spaces / Render</td>
      <td>Kolay ve Ã¼cretsiz yayÄ±nlama platformlarÄ±.</td>
    </tr>
  </tbody>
</table>

# âš™ï¸ Yerel Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

**Ã–n KoÅŸullar**
1. Python 3.11+
2. Docker Desktop (Konteyner Ã§alÄ±ÅŸtÄ±rmak iÃ§in)
3. Minimum 8GB RAM (Model bellekte Ã§alÄ±ÅŸÄ±r)

**AdÄ±mlar**
**1. AdÄ±m - Depoyu Klonla:**
```bash
git clone [DEPO ADRESÄ°NÄ°Z]
cd automatic_article_summarize
```

**2.AdÄ±m - Docket Ä°majÄ±nÄ± Ä°nÅŸa Et:**
```bash
# Bu komut, modeli (yaklaÅŸÄ±k 5 GB) indirir ve imajÄ± oluÅŸturur.
docker build -t makale-ozetleyici-mvp .
```

**3.AdÄ±m - Konteyneri BaÅŸlat:**
```bash
# FastAPI (8000) ve Streamlit (8501) portlarÄ±nÄ± aÃ§ar
docker run -p 8501:8501 makale-ozetleyici-mvp
```

*Uygulama baÅŸlatÄ±ldÄ±ktan sonra tarayÄ±cÄ±nÄ±zdan http://localhost:8501 adresine giderek kullanabilirsiniz.*

# ğŸ§  LLM MÃ¼hendisliÄŸi (Ã–nemli)
Bu projenin teknik gÃ¼cÃ¼, sadece model kullanmak yerine, yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ± garantisi Ã¼zerine kurulmuÅŸtur:
* **Prompt MÃ¼hendisliÄŸi:** Modele verilen talimat, Ã§Ä±ktÄ±nÄ±n kesinlikle TÃ¼rkÃ§e JSON formatÄ±nda olmasÄ±nÄ± ve belirli anahtarlarÄ± (veri_seti, metodoloji vb.) iÃ§ermesini zorlar.
* **JSON Temizleme:** LLM'lerin bazen JSON kod bloÄŸu (```json) ile yanÄ±t vermesi durumuna karÅŸÄ± Python kodu ile yanÄ±t temizlenir ve json.loads ile gÃ¼venli bir ÅŸekilde ayrÄ±ÅŸtÄ±rÄ±lÄ±r.